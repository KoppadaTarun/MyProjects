{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WLmtqmcoPgb",
        "outputId": "21f9914e-2680-48b4-ec91-54e3ee753a0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Collecting trl\n",
            "  Downloading trl-0.12.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.5.1+cu121)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (1.1.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from trl) (13.9.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
            "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.12.1-py3-none-any.whl (310 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.9/310.9 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, bitsandbytes, datasets, trl, evaluate\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bitsandbytes-0.44.1 datasets-3.1.0 dill-0.3.8 evaluate-0.4.3 fsspec-2024.9.0 multiprocess-0.70.16 trl-0.12.1 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets evaluate peft trl bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments, pipeline, logging\n",
        "from peft import LoraConfig\n",
        "from trl import SFTTrainer\n",
        "\n",
        "base_model = \"TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T\"\n",
        "guanco_dataset = \"mlabonne/guanaco-llama2-1k\"\n",
        "new_model = \"llama-1.1B-chat-guanaco\"\n",
        "\n",
        "dataset = load_dataset(guanco_dataset, split=\"train\")\n",
        "model = AutoModelForCausalLM.from_pretrained(base_model, device_map='auto')\n",
        "model.config.use_cache= False\n",
        "model.config.pretraining_tp = 1\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = 'right'\n"
      ],
      "metadata": {
        "id": "_5RDJspFrsHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run inference\n",
        "logging.set_verbosity(logging.CRITICAL)\n",
        "prompt = \"Who is Napoleon Bonaparte?\"\n",
        "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200)\n",
        "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
        "# print(result[0]['generated_text'])\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-crhf_qErsWJ",
        "outputId": "08a1955d-89dd-4118-db65-9699888f336c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'generated_text': '<s>[INST] Who is Napoleon Bonaparte? [/INST]\\n[INST] Who is Napoleon Bonaparte? [/INST]\\n[INST] Who is Napoleon Bonaparte? [/INST]\\n[INST] Who is Napoleon Bonaparte? [/INST]\\n[INST] Who is Napoleon Bonaparte? [/INST]\\n[INST] Who is Napoleon Bonaparte? [/INST]\\n[INST] Who is Napoleon Bonaparte? [/INST]\\n[INST] Who is Napoleon Bonaparte? [/INST]\\n[INST] Who is Napoleon Bonaparte? [/INST]\\n[INST] Who is Napoleon Bonaparte? [/INST]\\n[INST] Who is Napoleon Bonaparte? [/INST]\\n[INST] Who is Napoleon Bonaparte? [/INST]\\n[INST] Who is Napoleon Bonaparte? [/INST]\\n[INST]'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"WANDB_MODE\"]= \"disabled\""
      ],
      "metadata": {
        "id": "UxDkgACG18p2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "peft_params = LoraConfig(lora_alpha=16, #multiplier of lora output when its added to the full forward output\n",
        "                         lora_dropout=0.1,\n",
        "                         r=64,\n",
        "                         bias=\"none\",\n",
        "                         task_type=\"CASUAL_LM\")\n",
        "\n",
        "training_params = TrainingArguments(output_dir='./results',\n",
        "                                    num_train_epochs=2,\n",
        "                                    per_device_train_batch_size=2,\n",
        "                                    gradient_accumulation_steps=16,\n",
        "                                    optim=\"adamw_torch\",\n",
        "                                    save_steps=25,\n",
        "                                    logging_steps=1,\n",
        "                                    learning_rate=2e-4,\n",
        "                                    weight_decay=0.001,\n",
        "                                    fp16=True,\n",
        "                                    bf16=False,\n",
        "                                    max_grad_norm=0.3,\n",
        "                                    max_steps=-1,\n",
        "                                    warmup_ratio=0.03,\n",
        "                                    group_by_length=True,\n",
        "                                    lr_scheduler_type=\"cosine\")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset,\n",
        "    peft_config=peft_params,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length= None,\n",
        "    tokenizer= tokenizer,\n",
        "    args = training_params,\n",
        "    packing=False\n",
        ")\n",
        "\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "trainer.train()\n",
        "trainer.model.save_pretrained(new_model)\n",
        "trainer.tokenizer.save_pretrained(new_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9bWhdTgGrsYi",
        "outputId": "dd1e838d-6957-46b1-dbd5-9a5c04533770"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field. Will not be supported from version '0.13.0'.\n",
            "\n",
            "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:309: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 1.4743, 'grad_norm': 0.0625004842877388, 'learning_rate': 0.0001, 'epoch': 0.032}\n",
            "{'loss': 1.6063, 'grad_norm': 0.07649805396795273, 'learning_rate': 0.0002, 'epoch': 0.064}\n",
            "{'loss': 1.7181, 'grad_norm': 0.0671316534280777, 'learning_rate': 0.0001998629534754574, 'epoch': 0.096}\n",
            "{'loss': 1.7199, 'grad_norm': 0.0916563868522644, 'learning_rate': 0.00019945218953682734, 'epoch': 0.128}\n",
            "{'loss': 1.9804, 'grad_norm': 0.10270264744758606, 'learning_rate': 0.00019876883405951377, 'epoch': 0.16}\n",
            "{'loss': 2.1968, 'grad_norm': 0.14221307635307312, 'learning_rate': 0.00019781476007338058, 'epoch': 0.192}\n",
            "{'loss': 2.7359, 'grad_norm': 0.27412551641464233, 'learning_rate': 0.00019659258262890683, 'epoch': 0.224}\n",
            "{'loss': 1.6217, 'grad_norm': 0.08943010121583939, 'learning_rate': 0.00019510565162951537, 'epoch': 0.256}\n",
            "{'loss': 1.6594, 'grad_norm': 0.10465283691883087, 'learning_rate': 0.00019335804264972018, 'epoch': 0.288}\n",
            "{'loss': 1.765, 'grad_norm': 0.09990952908992767, 'learning_rate': 0.0001913545457642601, 'epoch': 0.32}\n",
            "{'loss': 1.7971, 'grad_norm': 0.12466183304786682, 'learning_rate': 0.0001891006524188368, 'epoch': 0.352}\n",
            "{'loss': 1.9965, 'grad_norm': 0.1605544090270996, 'learning_rate': 0.00018660254037844388, 'epoch': 0.384}\n",
            "{'loss': 1.9983, 'grad_norm': 0.2236654907464981, 'learning_rate': 0.00018386705679454242, 'epoch': 0.416}\n",
            "{'loss': 2.3657, 'grad_norm': 0.40125370025634766, 'learning_rate': 0.00018090169943749476, 'epoch': 0.448}\n",
            "{'loss': 1.4326, 'grad_norm': 0.10628937184810638, 'learning_rate': 0.0001777145961456971, 'epoch': 0.48}\n",
            "{'loss': 1.6475, 'grad_norm': 0.09515076130628586, 'learning_rate': 0.00017431448254773944, 'epoch': 0.512}\n",
            "{'loss': 1.6432, 'grad_norm': 0.09611758589744568, 'learning_rate': 0.00017071067811865476, 'epoch': 0.544}\n",
            "{'loss': 1.6008, 'grad_norm': 0.10370071232318878, 'learning_rate': 0.00016691306063588583, 'epoch': 0.576}\n",
            "{'loss': 1.7493, 'grad_norm': 0.1276518851518631, 'learning_rate': 0.00016293203910498376, 'epoch': 0.608}\n",
            "{'loss': 1.9208, 'grad_norm': 0.1576615273952484, 'learning_rate': 0.00015877852522924732, 'epoch': 0.64}\n",
            "{'loss': 2.1792, 'grad_norm': 0.3202686309814453, 'learning_rate': 0.00015446390350150273, 'epoch': 0.672}\n",
            "{'loss': 1.337, 'grad_norm': 0.07555039972066879, 'learning_rate': 0.00015000000000000001, 'epoch': 0.704}\n",
            "{'loss': 1.6318, 'grad_norm': 0.08630678057670593, 'learning_rate': 0.00014539904997395468, 'epoch': 0.736}\n",
            "{'loss': 1.6223, 'grad_norm': 0.1070326715707779, 'learning_rate': 0.00014067366430758004, 'epoch': 0.768}\n",
            "{'loss': 1.5369, 'grad_norm': 0.12776263058185577, 'learning_rate': 0.00013583679495453, 'epoch': 0.8}\n",
            "{'loss': 1.7693, 'grad_norm': 0.17136412858963013, 'learning_rate': 0.00013090169943749476, 'epoch': 0.832}\n",
            "{'loss': 2.0358, 'grad_norm': 0.23203954100608826, 'learning_rate': 0.00012588190451025207, 'epoch': 0.864}\n",
            "{'loss': 2.4482, 'grad_norm': 0.49285921454429626, 'learning_rate': 0.00012079116908177593, 'epoch': 0.896}\n",
            "{'loss': 1.4211, 'grad_norm': 0.09531837701797485, 'learning_rate': 0.0001156434465040231, 'epoch': 0.928}\n",
            "{'loss': 1.7274, 'grad_norm': 0.14433477818965912, 'learning_rate': 0.00011045284632676536, 'epoch': 0.96}\n",
            "{'loss': 1.8538, 'grad_norm': 0.308017373085022, 'learning_rate': 0.0001052335956242944, 'epoch': 0.992}\n",
            "{'loss': 3.4179, 'grad_norm': 0.9780792593955994, 'learning_rate': 0.0001, 'epoch': 1.024}\n",
            "{'loss': 1.4696, 'grad_norm': 0.09739922732114792, 'learning_rate': 9.476640437570562e-05, 'epoch': 1.056}\n",
            "{'loss': 1.6812, 'grad_norm': 0.11762062460184097, 'learning_rate': 8.954715367323468e-05, 'epoch': 1.088}\n",
            "{'loss': 1.5677, 'grad_norm': 0.12588895857334137, 'learning_rate': 8.435655349597689e-05, 'epoch': 1.12}\n",
            "{'loss': 1.6818, 'grad_norm': 0.15456300973892212, 'learning_rate': 7.920883091822408e-05, 'epoch': 1.152}\n",
            "{'loss': 1.9473, 'grad_norm': 0.23142029345035553, 'learning_rate': 7.411809548974792e-05, 'epoch': 1.184}\n",
            "{'loss': 2.1776, 'grad_norm': 0.39627566933631897, 'learning_rate': 6.909830056250527e-05, 'epoch': 1.216}\n",
            "{'loss': 1.4688, 'grad_norm': 0.19428689777851105, 'learning_rate': 6.416320504546997e-05, 'epoch': 1.248}\n",
            "{'loss': 1.4695, 'grad_norm': 0.08035542815923691, 'learning_rate': 5.9326335692419995e-05, 'epoch': 1.28}\n",
            "{'loss': 1.5558, 'grad_norm': 0.10027536004781723, 'learning_rate': 5.4600950026045326e-05, 'epoch': 1.312}\n",
            "{'loss': 1.498, 'grad_norm': 0.11417113989591599, 'learning_rate': 5.000000000000002e-05, 'epoch': 1.3439999999999999}\n",
            "{'loss': 1.6571, 'grad_norm': 0.13363656401634216, 'learning_rate': 4.5536096498497295e-05, 'epoch': 1.376}\n",
            "{'loss': 1.7827, 'grad_norm': 0.16104237735271454, 'learning_rate': 4.12214747707527e-05, 'epoch': 1.408}\n",
            "{'loss': 2.1821, 'grad_norm': 0.31817227602005005, 'learning_rate': 3.7067960895016275e-05, 'epoch': 1.44}\n",
            "{'loss': 1.5219, 'grad_norm': 0.1792478710412979, 'learning_rate': 3.308693936411421e-05, 'epoch': 1.472}\n",
            "{'loss': 1.3937, 'grad_norm': 0.08706099539995193, 'learning_rate': 2.9289321881345254e-05, 'epoch': 1.504}\n",
            "{'loss': 1.5702, 'grad_norm': 0.10754511505365372, 'learning_rate': 2.5685517452260567e-05, 'epoch': 1.536}\n",
            "{'loss': 1.5786, 'grad_norm': 0.11099014431238174, 'learning_rate': 2.2285403854302912e-05, 'epoch': 1.568}\n",
            "{'loss': 1.7072, 'grad_norm': 0.14903317391872406, 'learning_rate': 1.9098300562505266e-05, 'epoch': 1.6}\n",
            "{'loss': 1.842, 'grad_norm': 0.16733098030090332, 'learning_rate': 1.6132943205457606e-05, 'epoch': 1.6320000000000001}\n",
            "{'loss': 2.2307, 'grad_norm': 0.3185310363769531, 'learning_rate': 1.339745962155613e-05, 'epoch': 1.6640000000000001}\n",
            "{'loss': 1.3473, 'grad_norm': 0.15383176505565643, 'learning_rate': 1.0899347581163221e-05, 'epoch': 1.696}\n",
            "{'loss': 1.4446, 'grad_norm': 0.08688849955797195, 'learning_rate': 8.645454235739903e-06, 'epoch': 1.728}\n",
            "{'loss': 1.5453, 'grad_norm': 0.09399224072694778, 'learning_rate': 6.6419573502798374e-06, 'epoch': 1.76}\n",
            "{'loss': 1.5794, 'grad_norm': 0.11034618318080902, 'learning_rate': 4.8943483704846475e-06, 'epoch': 1.792}\n",
            "{'loss': 1.6373, 'grad_norm': 0.12552854418754578, 'learning_rate': 3.40741737109318e-06, 'epoch': 1.8239999999999998}\n",
            "{'loss': 1.6973, 'grad_norm': 0.1981883943080902, 'learning_rate': 2.1852399266194314e-06, 'epoch': 1.8559999999999999}\n",
            "{'loss': 2.1324, 'grad_norm': 0.3148221969604492, 'learning_rate': 1.231165940486234e-06, 'epoch': 1.888}\n",
            "{'loss': 1.5219, 'grad_norm': 0.17040029168128967, 'learning_rate': 5.478104631726711e-07, 'epoch': 1.92}\n",
            "{'loss': 1.4448, 'grad_norm': 0.09946928918361664, 'learning_rate': 1.3704652454261668e-07, 'epoch': 1.952}\n",
            "{'loss': 1.7528, 'grad_norm': 0.15840783715248108, 'learning_rate': 0.0, 'epoch': 1.984}\n",
            "{'train_runtime': 195.7668, 'train_samples_per_second': 10.216, 'train_steps_per_second': 0.317, 'train_loss': 1.7693101206133444, 'epoch': 1.984}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('llama-1.1B-chat-guanaco/tokenizer_config.json',\n",
              " 'llama-1.1B-chat-guanaco/special_tokens_map.json',\n",
              " 'llama-1.1B-chat-guanaco/tokenizer.model',\n",
              " 'llama-1.1B-chat-guanaco/added_tokens.json',\n",
              " 'llama-1.1B-chat-guanaco/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Who is Napoleon Bonaparte?\"\n",
        "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200)\n",
        "result = pipe(\"<s>[INST] {prompt} [/INST]\")\n",
        "print(result[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4VPO7jDrsaw",
        "outputId": "1afd389e-1ef8-4855-987e-90d461d3bc4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>[INST] Who is Napoleon Bonaparte? [/INST] Napoleon Bonaparte was a French military leader who led the French Revolution and the Napoleonic Empire. He was also a politician, philosopher, and writer. He was born in 1769 and died in 1821.\n",
            "Napoleon Bonaparte was a French military leader who led the French Revolution and the Napoleonic Empire. He was also a politician, philosopher, and writer. He was born in 1769 and died in 1821. Napoleon Bonaparte was a French military leader who led the French Revolution and the Napoleonic Empire. He was also a politician, philosopher, and writer. He was born in 1769 and died in 1821.\n",
            "Napoleon Bonaparte was a French military leader who led the French Revolution and the Napoleonic Empire. He was also\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Who is Donal trump?\"\n",
        "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200)\n",
        "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
        "print(result[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qz1MEhz-rseL",
        "outputId": "6ba18cf8-704c-469e-ec76-4626ef257858"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>[INST] Who is Donal trump? [/INST] Donal trump is a famous American politician who is currently serving as the 45th President of the United States of America. He was born on 14th September 1946 in New York City, New York, USA. He is the son of Donald Trump and Ivana Trump. He has two siblings, Donald Jr. and Ivanka. He graduated from the University of Pennsylvania with a degree in economics. He has been married to Melania Trump since 2005 and they have three children, Barron, Ivanka, and Eric. He is a Republican and has been a member of the Trump administration since 2017. He is known for his business acumen and his ability to negotiate deals. He is also known for his controversial statements and his use of social media. He is a popular figure in the political world\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NmK4mc8Orsmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TW5F_usjrso2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p2UndqiVrssM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}